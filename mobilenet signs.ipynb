{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PBhzYjntARm3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwcsbpCEcuEf",
        "outputId": "167bf2da-c6bf-4325-dc72-63651488443d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = '/content/drive/MyDrive/asl_alphabet_train'"
      ],
      "metadata": {
        "id": "Yfk_iKB_i1XU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R9K0Ud0TCaFX"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    \n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdCfpmhkFGw-",
        "outputId": "ae085f9e-a976-4573-8e15-f8e62995aae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4-clSKckPX_",
        "outputId": "aaf1e101-9a19-47c6-a745-2136a28d3a24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQJauEG018oG",
        "outputId": "4ff36ab7-e827-4c8c-c536-fd40b9e9ac95"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "CJolV9LIkSQY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OjmZkCWalOmw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=3\n",
        "from torchvision.models import mobilenet_v2\n",
        "model=models.mobilenet_v2(pretrained=False)\n",
        "features = model.last_channel  # Access last_channel attribute\n",
        "model.classifier = nn.Linear(features, num_classes)  # Replace the final classification layer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6fWI5GTlT7O",
        "outputId": "ccc156da-3fce-4321-fa60-b2441b6d9b02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for param in model.parameters():\n",
        "#    param.requires_grad = False\n",
        "#model.classifier[-1] = nn.Linear(model.last_channel, num_classes)\n",
        "model = model.to(d)"
      ],
      "metadata": {
        "id": "OG8P1RuqlXtD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "id": "YJ8P5ZxJliBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aad057d-dd0b-4564-87f7-3bf8ebc78a76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    \n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "lct-uOFvlpiB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aG3j2mOvrqnS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=Adam(model.parameters(),lr=0.001)\n",
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "1C53LQGTlxTC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(r\"asl_alphabet_train\", transform=test_transforms)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_dataset.transform=train_transforms\n",
        "from torch.utils.data import DataLoader\n",
        "loader_train=DataLoader(train_dataset,batch_size=32,shuffle=True )\n",
        "loader_test=DataLoader(test_dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "yuQ7hGytmHt-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "total_steps = len(loader_train)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(loader_train):\n",
        "        images, labels = data[0].to(d), data[1].to(d)\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backprop and optimisation\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))"
      ],
      "metadata": {
        "id": "H4h07XhMmMav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5bc180a-1fe4-42ee-cdd4-1a1323c660a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [1/10], Step [200/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [2/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [2/10], Step [200/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [200/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [200/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [200/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [200/200], Loss: 0.0000, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [100/200], Loss: 0.0000, Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total=0\n",
        "  for image,label in loader_test:\n",
        "    images,label=images.to(d),labels.to(d)\n",
        "    result=model(images)\n",
        "    _,predicted=torch.max(result.data,1)\n",
        "    total=total+labels.size(0)\n",
        "    correct=correct+(predicted==labels).sum().items()\n",
        "    print(f'Accuracy {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "id": "mFWdHUlUsF4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSJca9AY7dMG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}