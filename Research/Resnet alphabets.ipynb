{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFMqjt4DwHUR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME']=\"simransohal\"\n",
        "os.environ['KAGGLE_KEY']=\"3aa7697cd9a4ba2a3715c4a29c0f0cb6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLOO6Btew4JP",
        "outputId": "aee1672d-2837-4e38-c3cc-1b07a06d78bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading asl-rgb-depth-fingerspelling-spelling-it-out.zip to /content\n",
            "100% 2.11G/2.11G [01:41<00:00, 24.0MB/s]\n",
            "100% 2.11G/2.11G [01:41<00:00, 22.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d mrgeislinger/asl-rgb-depth-fingerspelling-spelling-it-out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcuu6XXWw-S1",
        "outputId": "a735b84c-83c3-4a9f-e971-3a170ef550de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asl-rgb-depth-fingerspelling-spelling-it-out.zip  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rarc6yEjyJRC"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('asl-rgb-depth-fingerspelling-spelling-it-out.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XodsxbryQTe",
        "outputId": "cfa70deb-150c-45f5-c62c-d9e973ffd916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asl-rgb-depth-fingerspelling-spelling-it-out.zip  \u001b[0m\u001b[01;34mdataset5\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gysxU2qNyZbG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba71D5Kx1jjV"
      },
      "outputs": [],
      "source": [
        "d=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax7Mujtp12li",
        "outputId": "72480789-d658-483a-d3e1-ce8d8890ddf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model=models.resnet18(pretrained=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8WHAYP12-Q9",
        "outputId": "e23190a0-537c-4765-f9e1-da4385a11384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asl-rgb-depth-fingerspelling-spelling-it-out.zip  \u001b[0m\u001b[01;34mdataset5\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWXRoNNCTFvy"
      },
      "outputs": [],
      "source": [
        "#Getting the number of input features in fully connected layer\n",
        "#Model is to be classified in just three layers\n",
        "#Created a new layer and replaced the fully connected layer with it\n",
        "num_classes=24\n",
        "features=model.fc.in_features\n",
        "model.fc=nn.Linear(features,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTZeAEtDWUlt"
      },
      "outputs": [],
      "source": [
        "model=model.to(d)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFM4BErZUYr-",
        "outputId": "e2d9a125-a17e-4618-f424-d3e26ce28491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S59KGVITWghg"
      },
      "outputs": [],
      "source": [
        "#train_transformations=transforms.Compose([transforms.CenterCrop(224)])\n",
        "#test_transformation=transforms.Compose([transforms.ToTensor(),transforms.Resize(224),transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    \n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "RS1jZFwld8jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(r\"dataset5\",transform=test_transforms)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_dataset.transform=train_transforms\n"
      ],
      "metadata": {
        "id": "WFbKzd2PUZay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWNV0DMKgqx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "513f9f16-89e5-4cd9-ed22-62d11a2109f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-47b79dc828e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"asl_alphabet_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transformations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'asl_alphabet_train'"
          ]
        }
      ],
      "source": [
        "data=datasets.ImageFolder(r\"asl_alphabet_train\",transform=train_transformations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvjisi2Iq2y5"
      },
      "outputs": [],
      "source": [
        "test_data=datasets.ImageFolder(r\"asl_alphabet_test\",transform=test_transformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIa9KJiIrbHp"
      },
      "outputs": [],
      "source": [
        "optimizer=Adam(model.parameters(),lr=0.001)\n",
        "criterion=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDSQqxGqsCAE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loader_train=DataLoader(train_dataset,batch_size=32,shuffle=True )\n",
        "loader_test=DataLoader(test_dataset,batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images,labels in loader_train:\n",
        "  batch_size=images.shape[0]\n",
        "  "
      ],
      "metadata": {
        "id": "72o3iEdR4VQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDoo8KzntUy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fe5544-027e-417c-8fde-da058bb1259c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/3292], Loss: 1.2704, Accuracy: 50.00%\n",
            "Epoch [1/10], Step [200/3292], Loss: 0.8992, Accuracy: 62.50%\n",
            "Epoch [1/10], Step [300/3292], Loss: 0.7912, Accuracy: 71.88%\n",
            "Epoch [1/10], Step [400/3292], Loss: 0.8741, Accuracy: 65.62%\n",
            "Epoch [1/10], Step [500/3292], Loss: 0.6834, Accuracy: 75.00%\n",
            "Epoch [1/10], Step [600/3292], Loss: 0.6071, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [700/3292], Loss: 0.7640, Accuracy: 62.50%\n",
            "Epoch [1/10], Step [800/3292], Loss: 0.5772, Accuracy: 78.12%\n",
            "Epoch [1/10], Step [900/3292], Loss: 0.3896, Accuracy: 84.38%\n",
            "Epoch [1/10], Step [1000/3292], Loss: 0.4905, Accuracy: 75.00%\n",
            "Epoch [1/10], Step [1100/3292], Loss: 0.8322, Accuracy: 59.38%\n",
            "Epoch [1/10], Step [1200/3292], Loss: 0.5031, Accuracy: 75.00%\n",
            "Epoch [1/10], Step [1300/3292], Loss: 0.3427, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [1400/3292], Loss: 0.3285, Accuracy: 87.50%\n",
            "Epoch [1/10], Step [1500/3292], Loss: 0.4947, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [1600/3292], Loss: 0.3250, Accuracy: 87.50%\n",
            "Epoch [1/10], Step [1700/3292], Loss: 0.4676, Accuracy: 78.12%\n",
            "Epoch [1/10], Step [1800/3292], Loss: 0.3318, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [1900/3292], Loss: 0.3769, Accuracy: 78.12%\n",
            "Epoch [1/10], Step [2000/3292], Loss: 0.1776, Accuracy: 90.62%\n",
            "Epoch [1/10], Step [2100/3292], Loss: 0.2081, Accuracy: 87.50%\n",
            "Epoch [1/10], Step [2200/3292], Loss: 0.3572, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [2300/3292], Loss: 0.3193, Accuracy: 84.38%\n",
            "Epoch [1/10], Step [2400/3292], Loss: 0.8442, Accuracy: 59.38%\n",
            "Epoch [1/10], Step [2500/3292], Loss: 0.4300, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [2600/3292], Loss: 0.2638, Accuracy: 87.50%\n",
            "Epoch [1/10], Step [2700/3292], Loss: 0.3343, Accuracy: 87.50%\n",
            "Epoch [1/10], Step [2800/3292], Loss: 0.3136, Accuracy: 81.25%\n",
            "Epoch [1/10], Step [2900/3292], Loss: 0.1855, Accuracy: 90.62%\n",
            "Epoch [1/10], Step [3000/3292], Loss: 0.2180, Accuracy: 90.62%\n",
            "Epoch [1/10], Step [3100/3292], Loss: 0.1679, Accuracy: 93.75%\n",
            "Epoch [1/10], Step [3200/3292], Loss: 0.2934, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [100/3292], Loss: 0.3804, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [200/3292], Loss: 0.1320, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [300/3292], Loss: 0.1421, Accuracy: 90.62%\n",
            "Epoch [2/10], Step [400/3292], Loss: 0.2921, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [500/3292], Loss: 0.1391, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [600/3292], Loss: 0.3064, Accuracy: 84.38%\n",
            "Epoch [2/10], Step [700/3292], Loss: 0.1584, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [800/3292], Loss: 0.1651, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [900/3292], Loss: 0.4169, Accuracy: 81.25%\n",
            "Epoch [2/10], Step [1000/3292], Loss: 0.3890, Accuracy: 84.38%\n",
            "Epoch [2/10], Step [1100/3292], Loss: 0.2140, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [1200/3292], Loss: 0.1274, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [1300/3292], Loss: 0.2959, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [1400/3292], Loss: 0.1858, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [1500/3292], Loss: 0.1155, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [1600/3292], Loss: 0.0779, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [1700/3292], Loss: 0.1963, Accuracy: 93.75%\n",
            "Epoch [2/10], Step [1800/3292], Loss: 0.1255, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [1900/3292], Loss: 0.2946, Accuracy: 84.38%\n",
            "Epoch [2/10], Step [2000/3292], Loss: 0.2769, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [2100/3292], Loss: 0.1299, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [2200/3292], Loss: 0.2341, Accuracy: 90.62%\n",
            "Epoch [2/10], Step [2300/3292], Loss: 0.3919, Accuracy: 87.50%\n",
            "Epoch [2/10], Step [2400/3292], Loss: 0.1276, Accuracy: 93.75%\n",
            "Epoch [2/10], Step [2500/3292], Loss: 0.2761, Accuracy: 90.62%\n",
            "Epoch [2/10], Step [2600/3292], Loss: 0.0760, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [2700/3292], Loss: 0.1354, Accuracy: 93.75%\n",
            "Epoch [2/10], Step [2800/3292], Loss: 0.2329, Accuracy: 90.62%\n",
            "Epoch [2/10], Step [2900/3292], Loss: 0.1623, Accuracy: 96.88%\n",
            "Epoch [2/10], Step [3000/3292], Loss: 0.3247, Accuracy: 84.38%\n",
            "Epoch [2/10], Step [3100/3292], Loss: 0.2183, Accuracy: 93.75%\n",
            "Epoch [2/10], Step [3200/3292], Loss: 0.3365, Accuracy: 90.62%\n",
            "Epoch [3/10], Step [100/3292], Loss: 0.0571, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [200/3292], Loss: 0.1844, Accuracy: 90.62%\n",
            "Epoch [3/10], Step [300/3292], Loss: 0.0490, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [400/3292], Loss: 0.2321, Accuracy: 84.38%\n",
            "Epoch [3/10], Step [500/3292], Loss: 0.1444, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [600/3292], Loss: 0.0699, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [700/3292], Loss: 0.1293, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [800/3292], Loss: 0.0695, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [900/3292], Loss: 0.0733, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [1000/3292], Loss: 0.1102, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [1100/3292], Loss: 0.1294, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [1200/3292], Loss: 0.1110, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [1300/3292], Loss: 0.0983, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [1400/3292], Loss: 0.0414, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [1500/3292], Loss: 0.0798, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [1600/3292], Loss: 0.5411, Accuracy: 84.38%\n",
            "Epoch [3/10], Step [1700/3292], Loss: 0.1855, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [1800/3292], Loss: 0.0356, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [1900/3292], Loss: 0.0877, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [2000/3292], Loss: 0.0722, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [2100/3292], Loss: 0.1409, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [2200/3292], Loss: 0.1334, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [2300/3292], Loss: 0.2442, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [2400/3292], Loss: 0.0868, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [2500/3292], Loss: 0.0278, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [2600/3292], Loss: 0.0663, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [2700/3292], Loss: 0.0457, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [2800/3292], Loss: 0.1003, Accuracy: 96.88%\n",
            "Epoch [3/10], Step [2900/3292], Loss: 0.0342, Accuracy: 100.00%\n",
            "Epoch [3/10], Step [3000/3292], Loss: 0.1511, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [3100/3292], Loss: 0.1025, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [3200/3292], Loss: 0.0765, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [100/3292], Loss: 0.0643, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [200/3292], Loss: 0.0535, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [300/3292], Loss: 0.0643, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [400/3292], Loss: 0.0393, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [500/3292], Loss: 0.0304, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [600/3292], Loss: 0.1562, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [700/3292], Loss: 0.0876, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [800/3292], Loss: 0.0819, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [900/3292], Loss: 0.1551, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [1000/3292], Loss: 0.0361, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [1100/3292], Loss: 0.1146, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [1200/3292], Loss: 0.0196, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [1300/3292], Loss: 0.0703, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [1400/3292], Loss: 0.1449, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [1500/3292], Loss: 0.0775, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [1600/3292], Loss: 0.1379, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [1700/3292], Loss: 0.0299, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [1800/3292], Loss: 0.0172, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [1900/3292], Loss: 0.1275, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [2000/3292], Loss: 0.2414, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [2100/3292], Loss: 0.0640, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [2200/3292], Loss: 0.0696, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [2300/3292], Loss: 0.1674, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [2400/3292], Loss: 0.0815, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [2500/3292], Loss: 0.1251, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [2600/3292], Loss: 0.0674, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [2700/3292], Loss: 0.0928, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [2800/3292], Loss: 0.1502, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [2900/3292], Loss: 0.0329, Accuracy: 100.00%\n",
            "Epoch [4/10], Step [3000/3292], Loss: 0.1324, Accuracy: 93.75%\n",
            "Epoch [4/10], Step [3100/3292], Loss: 0.0667, Accuracy: 96.88%\n",
            "Epoch [4/10], Step [3200/3292], Loss: 0.1872, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [100/3292], Loss: 0.0332, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [200/3292], Loss: 0.0285, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [300/3292], Loss: 0.1952, Accuracy: 90.62%\n",
            "Epoch [5/10], Step [400/3292], Loss: 0.0187, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [500/3292], Loss: 0.0561, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [600/3292], Loss: 0.0389, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [700/3292], Loss: 0.0878, Accuracy: 93.75%\n",
            "Epoch [5/10], Step [800/3292], Loss: 0.0374, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [900/3292], Loss: 0.1350, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [1000/3292], Loss: 0.0549, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [1100/3292], Loss: 0.0261, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [1200/3292], Loss: 0.0336, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [1300/3292], Loss: 0.0138, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [1400/3292], Loss: 0.1118, Accuracy: 93.75%\n",
            "Epoch [5/10], Step [1500/3292], Loss: 0.0640, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [1600/3292], Loss: 0.0147, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [1700/3292], Loss: 0.0171, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [1800/3292], Loss: 0.0397, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [1900/3292], Loss: 0.1820, Accuracy: 93.75%\n",
            "Epoch [5/10], Step [2000/3292], Loss: 0.0232, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [2100/3292], Loss: 0.1054, Accuracy: 93.75%\n",
            "Epoch [5/10], Step [2200/3292], Loss: 0.1548, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [2300/3292], Loss: 0.0224, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [2400/3292], Loss: 0.0327, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [2500/3292], Loss: 0.0071, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [2600/3292], Loss: 0.0686, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [2700/3292], Loss: 0.0660, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [2800/3292], Loss: 0.0599, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [2900/3292], Loss: 0.0633, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [3000/3292], Loss: 0.0119, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [3100/3292], Loss: 0.0241, Accuracy: 100.00%\n",
            "Epoch [5/10], Step [3200/3292], Loss: 0.0131, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [100/3292], Loss: 0.0129, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [200/3292], Loss: 0.0344, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [300/3292], Loss: 0.0108, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [400/3292], Loss: 0.0548, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [500/3292], Loss: 0.0061, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [600/3292], Loss: 0.0150, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [700/3292], Loss: 0.0483, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [800/3292], Loss: 0.0008, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [900/3292], Loss: 0.0076, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1000/3292], Loss: 0.0459, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [1100/3292], Loss: 0.0149, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1200/3292], Loss: 0.0304, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1300/3292], Loss: 0.0312, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1400/3292], Loss: 0.0234, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1500/3292], Loss: 0.0425, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1600/3292], Loss: 0.1708, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [1700/3292], Loss: 0.1109, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [1800/3292], Loss: 0.0174, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [1900/3292], Loss: 0.0767, Accuracy: 93.75%\n",
            "Epoch [6/10], Step [2000/3292], Loss: 0.0030, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [2100/3292], Loss: 0.0468, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [2200/3292], Loss: 0.0119, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [2300/3292], Loss: 0.0115, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [2400/3292], Loss: 0.0821, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [2500/3292], Loss: 0.1689, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [2600/3292], Loss: 0.0505, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [2700/3292], Loss: 0.0087, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [2800/3292], Loss: 0.0274, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [2900/3292], Loss: 0.0585, Accuracy: 96.88%\n",
            "Epoch [6/10], Step [3000/3292], Loss: 0.1322, Accuracy: 93.75%\n",
            "Epoch [6/10], Step [3100/3292], Loss: 0.0062, Accuracy: 100.00%\n",
            "Epoch [6/10], Step [3200/3292], Loss: 0.0238, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [100/3292], Loss: 0.0009, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [200/3292], Loss: 0.0037, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [300/3292], Loss: 0.0453, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [400/3292], Loss: 0.0426, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [500/3292], Loss: 0.0348, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [600/3292], Loss: 0.0098, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [700/3292], Loss: 0.0023, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [800/3292], Loss: 0.0176, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [900/3292], Loss: 0.0647, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [1000/3292], Loss: 0.0043, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [1100/3292], Loss: 0.0120, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [1200/3292], Loss: 0.0018, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [1300/3292], Loss: 0.0201, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [1400/3292], Loss: 0.0550, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [1500/3292], Loss: 0.0058, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [1600/3292], Loss: 0.0323, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [1700/3292], Loss: 0.0819, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [1800/3292], Loss: 0.0050, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [1900/3292], Loss: 0.0051, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2000/3292], Loss: 0.0048, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2100/3292], Loss: 0.0296, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2200/3292], Loss: 0.0997, Accuracy: 93.75%\n",
            "Epoch [7/10], Step [2300/3292], Loss: 0.1603, Accuracy: 93.75%\n",
            "Epoch [7/10], Step [2400/3292], Loss: 0.0042, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2500/3292], Loss: 0.0260, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [2600/3292], Loss: 0.0294, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2700/3292], Loss: 0.0118, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2800/3292], Loss: 0.0412, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [2900/3292], Loss: 0.2373, Accuracy: 96.88%\n",
            "Epoch [7/10], Step [3000/3292], Loss: 0.0105, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [3100/3292], Loss: 0.0022, Accuracy: 100.00%\n",
            "Epoch [7/10], Step [3200/3292], Loss: 0.0055, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [100/3292], Loss: 0.0021, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [200/3292], Loss: 0.0037, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [300/3292], Loss: 0.0010, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [400/3292], Loss: 0.0034, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [500/3292], Loss: 0.0167, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [600/3292], Loss: 0.0077, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [700/3292], Loss: 0.0063, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [800/3292], Loss: 0.0011, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [900/3292], Loss: 0.0056, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1000/3292], Loss: 0.0145, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1100/3292], Loss: 0.0235, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1200/3292], Loss: 0.0057, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1300/3292], Loss: 0.0038, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1400/3292], Loss: 0.0221, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1500/3292], Loss: 0.0054, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1600/3292], Loss: 0.0018, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1700/3292], Loss: 0.0064, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [1800/3292], Loss: 0.1498, Accuracy: 96.88%\n",
            "Epoch [8/10], Step [1900/3292], Loss: 0.0112, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [2000/3292], Loss: 0.0361, Accuracy: 96.88%\n",
            "Epoch [8/10], Step [2100/3292], Loss: 0.0207, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [2200/3292], Loss: 0.2570, Accuracy: 96.88%\n",
            "Epoch [8/10], Step [2300/3292], Loss: 0.0827, Accuracy: 93.75%\n",
            "Epoch [8/10], Step [2400/3292], Loss: 0.0785, Accuracy: 93.75%\n",
            "Epoch [8/10], Step [2500/3292], Loss: 0.0025, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [2600/3292], Loss: 0.0127, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [2700/3292], Loss: 0.0169, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [2800/3292], Loss: 0.0051, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [2900/3292], Loss: 0.0009, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [3000/3292], Loss: 0.0467, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [3100/3292], Loss: 0.0076, Accuracy: 100.00%\n",
            "Epoch [8/10], Step [3200/3292], Loss: 0.0026, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [100/3292], Loss: 0.0150, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [200/3292], Loss: 0.0015, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [300/3292], Loss: 0.0090, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [400/3292], Loss: 0.0188, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [500/3292], Loss: 0.0022, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [600/3292], Loss: 0.0502, Accuracy: 96.88%\n",
            "Epoch [9/10], Step [700/3292], Loss: 0.0679, Accuracy: 96.88%\n",
            "Epoch [9/10], Step [800/3292], Loss: 0.0020, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [900/3292], Loss: 0.0627, Accuracy: 96.88%\n",
            "Epoch [9/10], Step [1000/3292], Loss: 0.0035, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1100/3292], Loss: 0.0035, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1200/3292], Loss: 0.0247, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1300/3292], Loss: 0.0107, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1400/3292], Loss: 0.0238, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1500/3292], Loss: 0.0080, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1600/3292], Loss: 0.0058, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1700/3292], Loss: 0.0989, Accuracy: 96.88%\n",
            "Epoch [9/10], Step [1800/3292], Loss: 0.0182, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [1900/3292], Loss: 0.0022, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2000/3292], Loss: 0.0054, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2100/3292], Loss: 0.0133, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2200/3292], Loss: 0.0058, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2300/3292], Loss: 0.0008, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2400/3292], Loss: 0.0311, Accuracy: 96.88%\n",
            "Epoch [9/10], Step [2500/3292], Loss: 0.0516, Accuracy: 96.88%\n",
            "Epoch [9/10], Step [2600/3292], Loss: 0.0029, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2700/3292], Loss: 0.0090, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2800/3292], Loss: 0.0006, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [2900/3292], Loss: 0.0057, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [3000/3292], Loss: 0.0028, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [3100/3292], Loss: 0.0221, Accuracy: 100.00%\n",
            "Epoch [9/10], Step [3200/3292], Loss: 0.0004, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [100/3292], Loss: 0.0085, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [200/3292], Loss: 0.0519, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [300/3292], Loss: 0.0535, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [400/3292], Loss: 0.0388, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [500/3292], Loss: 0.0021, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [600/3292], Loss: 0.0079, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [700/3292], Loss: 0.0285, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [800/3292], Loss: 0.0089, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [900/3292], Loss: 0.0352, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [1000/3292], Loss: 0.0002, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [1100/3292], Loss: 0.0412, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [1200/3292], Loss: 0.0111, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [1300/3292], Loss: 0.0502, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [1400/3292], Loss: 0.0230, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [1500/3292], Loss: 0.1067, Accuracy: 93.75%\n",
            "Epoch [10/10], Step [1600/3292], Loss: 0.0001, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [1700/3292], Loss: 0.2070, Accuracy: 90.62%\n",
            "Epoch [10/10], Step [1800/3292], Loss: 0.0109, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [1900/3292], Loss: 0.0268, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [2000/3292], Loss: 0.0252, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2100/3292], Loss: 0.0075, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2200/3292], Loss: 0.0069, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2300/3292], Loss: 0.0067, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2400/3292], Loss: 0.0292, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [2500/3292], Loss: 0.0361, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2600/3292], Loss: 0.0656, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [2700/3292], Loss: 0.0013, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2800/3292], Loss: 0.0177, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [2900/3292], Loss: 0.0013, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [3000/3292], Loss: 0.0015, Accuracy: 100.00%\n",
            "Epoch [10/10], Step [3100/3292], Loss: 0.2413, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [3200/3292], Loss: 0.1127, Accuracy: 96.88%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "total_steps = len(loader_train)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(loader_train):\n",
        "        images, labels = data[0].to(d), data[1].to(d)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nCWbn99pqFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7242559-b542-4ba0-dc1e-c14278a40c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n",
            "Accuracy 100.00%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total=0\n",
        "  for image,label in loader_test:\n",
        "    images,label=images.to(d),labels.to(d)\n",
        "    result=model(images)\n",
        "    _,predicted=torch.max(result.data,1)\n",
        "    total=total+labels.size(0)\n",
        "    correct=correct+(predicted==labels).sum().item()\n",
        "    print(f'Accuracy {100 * correct / total:.2f}%')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxR1BKvsuSJt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}