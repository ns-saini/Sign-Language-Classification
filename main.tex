  % CVPR 2022 Paper Template
  % based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
  % modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

  \documentclass[10pt,twocolumn,letterpaper]{article}

  %%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
  \usepackage[review]{cvpr}      % To produce the REVIEW version
  %\usepackage{cvpr}              % To produce the CAMERA-READY version
  %\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

  % Include other packages here, before hyperref.
  \usepackage{graphicx}
  \usepackage{amsmath}
  \usepackage{amssymb}
  \usepackage{booktabs}
  \usepackage{graphicx}
  \usepackage{url}
  \usepackage{hyperref}
\graphicspath{ {.} }


  % It is strongly recommended to use hyperref, especially for the review version.
  % hyperref with option pagebackref eases the reviewers' job.
  % Please disable hyperref *only* if you encounter grave issues, e.g. with the
  % file validation for the camera-ready version.
  %
  % If you comment hyperref and then uncomment it, you should delete
  % ReviewTempalte.aux before re-running LaTeX.
  % (Or just hit 'q' on the first LaTeX run, let it finish, and you
  %  should be clear).
  \usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


  % Support for easy cross-referencing
  \usepackage[capitalize]{cleveref}
  \crefname{section}{Sec.}{Secs.}
  \Crefname{section}{Section}{Sections}
  \Crefname{table}{Table}{Tables}
  \crefname{table}{Tab.}{Tabs.}


  \begin{document}

  %%%%%%%%% TITLE - PLEASE UPDATE
  \title{\LaTeX\ Author Guidelines for \confName~Proceedings}

  \author{First Author\\ asdfds
  Institution1\\
  Institution1 address\\
  {\tt\small firstauthor@i1.org}
  % For a paper whose authors are all at the same institution,
  % omit the following lines up until the closing ``}''.
  % Additional authors and addresses can be added with ``\and'',
  % just like the second author.
  % To save space, use either the email address or home page, not both
  % \and
  % Second Author\\
  % Institution2\\
  % First line of institution2 address\\
  % {\tt\small secondauthor@i2.org}
  }
  \maketitle


  %%%%%%%%% BODY TEXT
  \section{Introduction}
  \label{sec:intro}

Sign language is the most important way for the deaf to communicate. The problem faced is to identify the twenty-six characters of the English alphabet and the white space. The most probable challenges that will be faced will be the correct classification of similar looking alphabets. By using CNN, we are trying to correctly classify the image as a character. For the purpose of diversifying the results we will be using the Mobile-Net-v3, ShuffleNet and ResNet-18 neural network to model three different datasets and then later train two models by making use of Transfer Learning.
\par
{\bfseries Application}: The conversion of sign language to text can prove to be quite helpful to not only the deaf people but also to others who do not understand the language. Furthermore, it will save costs of employing an intermediary for conversation between speakers and non speakers. It will also lead to better documentation, as saving long videos can be quite memory inefficient but saving the conversations in the form of text can be quite helpful.
\par
{\bfseries Goal} : The primary goal of the project is to predict the textual counterpart of a sign language image with high accuracy. In the end we will evaluate the accuracy using confusion matrix by comparing the results for each of the characters.


  %------------------------------------------------------------------------
  \section{Image Dataset Selection}
  \label{sec:formatting}
The American sign language has a diverse range of data across the web. For our usecase, we have selected 3 datasets which are suitable based on the number of classes and how skewed are the datasets and also based on the size of images which would be a factor during preprocessing of this data. The first dataset is provided by NIDCD, which is an gov. institution, this dataset would be trimmed to use only 3 classes out of 29. The second dataset has 28 classes, but the number of images are higher i.e 160k these would be systematically reduced to less 50k using random sampling. The model would be trained for all the classes for the second dataset.
The third dataset being used is the one provided by the paper \textbf{Spelling It Out}  paper which has about 132k images and 24 classes from 5 different individuals providing variety to the dataset. This dataset shall also be trimmed to less than 50k images divided equally among all the classes.

  \begin{table}
    \centering
    \begin{tabular}{l l l l}
      \toprule
      Parameters & Dataset 1 & Dataset 2 & Dataset 3\\
      \midrule
      Classes & 3 & 28 & 24\\
      Images & 87k & 166k & 132k \\
      Image Size & 200x200  & 400x400 & variable\\
      Format & .jpg & .jpg & .jpg \\
      Link & \href{https://www.kaggle.com/datasets/grassknoted/asl-alphabet}{Link} & \href{https://www.kaggle.com/datasets/kapillondhe/american-sign-language}{Link} & \href{https://www.kaggle.com/datasets/mrgeislinger/asl-rgb-depth-fingerspelling-spelling-it-out}{Link}\\
      \bottomrule
    \end{tabular}
    \caption{Datasets}
    \label{tab:example}
  \end{table}


  %-------------------------------------------------------------------------
  \section{Possible Methodology}
We are planning to work on Google Collab throughout our project and use Github for collaboration and version control our project. We plan to clean and pre-process the raw dataset by removing redundant images and making sure that the dataset is completely balanced.The three architectures that we will be using are: \textbf{Mobile-Net-v3, ShuffleNet, and ResNet-18}. Mobile-Net-v3 is a Convolution Neural Network(CNN) that is said to perform well for mobile devices. We are using Mobile-Net-v3 to reduce the training time of the images significantly since the number of parameters to be trained are low. ShuffleNet is yet another architecture that performs well for mobile devices. One added advantage here is that ShuffleNet has limited computation power without compromising the accuracy ResNet-18 is usually recommended for image classification problems. The architecture has many layers because of which it can accurately represent features, thus increasing its classification powers. We would we using optimization algorithms such as AdaDelta and Adam. Although both the optimization algorithm are computationally expensive, we believe that they will might significantly improve the learning rate of the model. Apart from using optimization algorithms, we would use k cross validation to obtain reliable results and avoid overfitting. To evaluate how well our model performs, we would be using different evaluation metrics such as precision, recall and f1 score.

\pagebreak

  %-------------------------------------------------------------------------
  \section{Gantt Chart}

  \includegraphics[scale=0.5]{{gantt.jpg}}

\pagebreak
  %-------------------------------------------------------------------------
  \section{References}

  List and number all bibliographical references in 9-point Times, single-spaced, at the end of your paper.
  When referenced in the text, enclose the citation number in square brackets, for
  example~\cite{Authors14}.
  Where appropriate, include page numbers and the name(s) of editors of referenced books.
  When you cite multiple papers at once, please make sure that you cite them in numerical order like this \cite{Alpher01,Alpher02,Alpher03,Alpher04,Alpher05}.
  If you use the template as advised, this will be taken care of automatically.


  



  %%%%%%%%% REFERENCES
  {\small
  \bibliographystyle{ieee_fullname}
  \bibliography{egbib}
  }

  \end{document}
